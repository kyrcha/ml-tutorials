<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Kyriakos Chatzidimitriou" />

<meta name="date" content="2016-11-10" />

<title>Decision Trees in R</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/highlight/textmate.css"
      type="text/css" />
<script src="site_libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ML & R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="r.html">R</a>
</li>
<li>
  <a href="classification.html">Classification</a>
</li>
<li>
  <a href="uc.html">Clustering</a>
</li>
<li>
  <a href="data-eng.html">Data Engineering</a>
</li>
<li>
  <a href="finder.html">Finder</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Decision Trees in R</h1>
<h4 class="author"><em>Kyriakos Chatzidimitriou</em></h4>
<h4 class="date"><em>November 10, 2016</em></h4>

</div>


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The goal of this notebook is to introduce how to induce decision trees in R using the <code>party</code> and <code>rpart</code> packages. For this example we are going to use the <a href="http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29">Breast Cancer Wisconsin (Original) Data Set</a> and in particular the <a href="http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data">breast-cancer-wisconsin.data file</a> from the <a href="http://archive.ics.uci.edu/ml/index.html">UCI Machine Learning Repository</a>.</p>
</div>
<div id="loading-the-data" class="section level2">
<h2>Loading the data</h2>
<p>First we are going to load the dataset as a dataframe. We are assuming that the current working directory is in the same directory where the dataset is stored. We add the <code>sep</code> option because the default separator is the empty string. In addition, as one can observe from the dataset instructions, the missing values are denoted with <code>?</code>. To check the documentation of the <code>read.table</code> function use the command <code>?read.table</code>.</p>
<pre class="r"><code># Downloading the file
fileURL &lt;- &quot;http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data&quot;
download.file(fileURL, destfile=&quot;breast-cancer-wisconsin.data&quot;, method=&quot;curl&quot;)
# read the data
data &lt;- read.table(&quot;breast-cancer-wisconsin.data&quot;, na.strings = &quot;?&quot;, sep=&quot;,&quot;)
str(data)</code></pre>
<pre><code>## &#39;data.frame&#39;:    699 obs. of  11 variables:
##  $ V1 : int  1000025 1002945 1015425 1016277 1017023 1017122 1018099 1018561 1033078 1033078 ...
##  $ V2 : int  5 5 3 6 4 8 1 2 2 4 ...
##  $ V3 : int  1 4 1 8 1 10 1 1 1 2 ...
##  $ V4 : int  1 4 1 8 1 10 1 2 1 1 ...
##  $ V5 : int  1 5 1 1 3 8 1 1 1 1 ...
##  $ V6 : int  2 7 2 3 2 7 2 2 2 2 ...
##  $ V7 : int  1 10 2 4 1 10 10 1 1 1 ...
##  $ V8 : int  3 3 3 3 3 9 3 3 1 2 ...
##  $ V9 : int  1 2 1 7 1 7 1 1 1 1 ...
##  $ V10: int  1 1 1 1 1 1 1 1 5 1 ...
##  $ V11: int  2 2 2 2 2 4 2 2 2 2 ...</code></pre>
<p>We won’t be needing the id number (1st column), because it is not an informative attribute, so let’s remove it.</p>
<pre class="r"><code>data &lt;- data[,-1]</code></pre>
<p>Let’s put names in the columns</p>
<pre class="r"><code>names(data) &lt;- c(&quot;ClumpThickness&quot;,
&quot;UniformityCellSize&quot;,
&quot;UniformityCellShape&quot;,
&quot;MarginalAdhesion&quot;,
&quot;SingleEpithelialCellSize&quot;,
&quot;BareNuclei&quot;,
&quot;BlandChromatin&quot;,
&quot;NormalNucleoli&quot;,
&quot;Mitoses&quot;,
&quot;Class&quot;)</code></pre>
<p>Also let???s make the Class column a categorical value, aka a factor in R</p>
<pre class="r"><code>data$Class &lt;- factor(data$Class, levels=c(2,4), labels=c(&quot;benign&quot;, &quot;malignant&quot;))</code></pre>
<p>Now let???s see a summary of the data:</p>
<pre class="r"><code>print(summary(data))</code></pre>
<pre><code>##  ClumpThickness   UniformityCellSize UniformityCellShape MarginalAdhesion
##  Min.   : 1.000   Min.   : 1.000     Min.   : 1.000      Min.   : 1.000  
##  1st Qu.: 2.000   1st Qu.: 1.000     1st Qu.: 1.000      1st Qu.: 1.000  
##  Median : 4.000   Median : 1.000     Median : 1.000      Median : 1.000  
##  Mean   : 4.418   Mean   : 3.134     Mean   : 3.207      Mean   : 2.807  
##  3rd Qu.: 6.000   3rd Qu.: 5.000     3rd Qu.: 5.000      3rd Qu.: 4.000  
##  Max.   :10.000   Max.   :10.000     Max.   :10.000      Max.   :10.000  
##                                                                          
##  SingleEpithelialCellSize   BareNuclei     BlandChromatin  
##  Min.   : 1.000           Min.   : 1.000   Min.   : 1.000  
##  1st Qu.: 2.000           1st Qu.: 1.000   1st Qu.: 2.000  
##  Median : 2.000           Median : 1.000   Median : 3.000  
##  Mean   : 3.216           Mean   : 3.545   Mean   : 3.438  
##  3rd Qu.: 4.000           3rd Qu.: 6.000   3rd Qu.: 5.000  
##  Max.   :10.000           Max.   :10.000   Max.   :10.000  
##                           NA&#39;s   :16                       
##  NormalNucleoli      Mitoses             Class    
##  Min.   : 1.000   Min.   : 1.000   benign   :458  
##  1st Qu.: 1.000   1st Qu.: 1.000   malignant:241  
##  Median : 1.000   Median : 1.000                  
##  Mean   : 2.867   Mean   : 1.589                  
##  3rd Qu.: 4.000   3rd Qu.: 1.000                  
##  Max.   :10.000   Max.   :10.000                  
## </code></pre>
<p>The next step is to split the dataset into a training (70%) and a validation set (30%). For comparing later different models or the same models trained with differernt parameters, we are going to use the same training and validation set. Since we are splitting them randomly, we set a seed so that we maintain the same split throughout our experiments.</p>
<pre class="r"><code>set.seed(1234)
ind &lt;- sample(2, nrow(data), replace=TRUE, prob=c(0.7, 0.3))
trainData &lt;- data[ind==1,]
validationData &lt;- data[ind==2,]</code></pre>
</div>
<div id="training" class="section level2">
<h2>Training</h2>
<p>Now we load the libraries <code>rpart</code>, <code>rpart.plot</code> and <code>party</code>. If they are not in your system you will have to install them with the commands: <code>install.packages(&quot;rpart&quot;)</code>, <code>install.packages(&quot;rpart.plot&quot;)</code> and `install.packages(“party”).</p>
<pre class="r"><code>library(rpart)
library(rpart.plot)
library(party)</code></pre>
<pre><code>## Loading required package: methods</code></pre>
<pre><code>## Loading required package: grid</code></pre>
<pre><code>## Loading required package: mvtnorm</code></pre>
<pre><code>## Loading required package: modeltools</code></pre>
<pre><code>## Loading required package: stats4</code></pre>
<pre><code>## Loading required package: strucchange</code></pre>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## 
## Attaching package: &#39;zoo&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<pre><code>## Loading required package: sandwich</code></pre>
<div id="rpart" class="section level3">
<h3>rpart</h3>
<p>Let???s product a decision tree by training the induction algorithm on the train dataset. Check out the options of rpart with the command <code>?rpart</code>.</p>
<pre class="r"><code>tree = rpart(Class ~ ., data=trainData, method=&quot;class&quot;)</code></pre>
<p>One can also use a differrent split criterion like the entropy split decision rule:</p>
<pre class="r"><code>entTree = rpart(Class ~ ., data=trainData, method=&quot;class&quot;, parms=list(split=&quot;information&quot;))</code></pre>
<p>The tree in text form:</p>
<pre class="r"><code>print(tree)</code></pre>
<pre><code>## n= 485 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 485 171 benign (0.647422680 0.352577320)  
##    2) UniformityCellSize&lt; 2.5 292   9 benign (0.969178082 0.030821918)  
##      4) BareNuclei&lt; 4.5 280   1 benign (0.996428571 0.003571429) *
##      5) BareNuclei&gt;=4.5 12   4 malignant (0.333333333 0.666666667) *
##    3) UniformityCellSize&gt;=2.5 193  31 malignant (0.160621762 0.839378238)  
##      6) UniformityCellShape&lt; 2.5 15   3 benign (0.800000000 0.200000000) *
##      7) UniformityCellShape&gt;=2.5 178  19 malignant (0.106741573 0.893258427)  
##       14) UniformityCellSize&lt; 4.5 45  14 malignant (0.311111111 0.688888889)  
##         28) BareNuclei&lt; 2.5 10   2 benign (0.800000000 0.200000000) *
##         29) BareNuclei&gt;=2.5 35   6 malignant (0.171428571 0.828571429) *
##       15) UniformityCellSize&gt;=4.5 133   5 malignant (0.037593985 0.962406015) *</code></pre>
<p>And in a visual representation:</p>
<pre class="r"><code>plot(tree)
text(tree)</code></pre>
<p><img src="dt_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>A more advanced representation can be produced using the <code>rpart.plot</code> library as follows:</p>
<pre class="r"><code>rpart.plot(tree, extra = 104, nn = TRUE)</code></pre>
<p><img src="dt_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>The parameters of the decision tree method can be shown with the command:</p>
<pre class="r"><code>rpart.control()</code></pre>
<pre><code>## $minsplit
## [1] 20
## 
## $minbucket
## [1] 7
## 
## $cp
## [1] 0.01
## 
## $maxcompete
## [1] 4
## 
## $maxsurrogate
## [1] 5
## 
## $usesurrogate
## [1] 2
## 
## $surrogatestyle
## [1] 0
## 
## $maxdepth
## [1] 30
## 
## $xval
## [1] 10</code></pre>
<p>For their meaning you can check out the documentation <code>?rpart.control</code>. The most important of them are: - minsplit: the minimum number of observations that must exist in a node in order for a split to be attempted. - minbucket: the minimum number of observations in any terminal (leaf) node. - maxdepth: sets the maximum depth of any node of the final tree - cp: parameter controlling if the complexity for a given split is allowed and is set empirically. Bigger values equal more prunning.</p>
<pre class="r"><code># Usage
tree_with_params = rpart(Class ~ ., data=trainData, method=&quot;class&quot;, minsplit = 1, minbucket = 1, cp = -1)
rpart.plot(tree_with_params, extra = 104, nn = TRUE)</code></pre>
<p><img src="dt_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
</div>
<div id="party" class="section level3">
<h3>party</h3>
<p>Let???s also try the <code>party</code> library and the <code>ctree</code> function:</p>
<pre class="r"><code>library(party)
ctree = ctree(Class ~ ., data=trainData)
# print it
print(ctree)</code></pre>
<pre><code>## 
##   Conditional inference tree with 7 terminal nodes
## 
## Response:  Class 
## Inputs:  ClumpThickness, UniformityCellSize, UniformityCellShape, MarginalAdhesion, SingleEpithelialCellSize, BareNuclei, BlandChromatin, NormalNucleoli, Mitoses 
## Number of observations:  485 
## 
## 1) UniformityCellSize &lt;= 2; criterion = 1, statistic = 323.402
##   2) BareNuclei &lt;= 4; criterion = 1, statistic = 169.767
##     3) SingleEpithelialCellSize &lt;= 2; criterion = 1, statistic = 29.834
##       4)*  weights = 264 
##     3) SingleEpithelialCellSize &gt; 2
##       5)*  weights = 16 
##   2) BareNuclei &gt; 4
##     6)*  weights = 12 
## 1) UniformityCellSize &gt; 2
##   7) BareNuclei &lt;= 3; criterion = 1, statistic = 42.361
##     8) UniformityCellSize &lt;= 4; criterion = 1, statistic = 23.999
##       9)*  weights = 27 
##     8) UniformityCellSize &gt; 4
##       10)*  weights = 20 
##   7) BareNuclei &gt; 3
##     11) BlandChromatin &lt;= 4; criterion = 0.996, statistic = 12.225
##       12)*  weights = 50 
##     11) BlandChromatin &gt; 4
##       13)*  weights = 96</code></pre>
<pre class="r"><code># visualize it
plot(ctree, type=&quot;simple&quot;)</code></pre>
<p><img src="dt_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
</div>
<div id="evaluation" class="section level2">
<h2>Evaluation</h2>
<p>The final step is to print the results in the validation set. We will create a function that get as input a tree model, the validation data and the type of the tree and prints results in the console.</p>
<pre class="r"><code>evaluation &lt;- function(model, data, atype) {
  cat(&quot;\nConfusion matrix:\n&quot;)
  prediction = predict(model, data, type=atype)
  xtab = table(prediction, data$Class)
  print(xtab)
  cat(&quot;\nEvaluation:\n\n&quot;)
  accuracy = sum(prediction == data$Class)/length(data$Class)
  precision = xtab[1,1]/sum(xtab[,1])
  recall = xtab[1,1]/sum(xtab[1,])
  f = 2 * (precision * recall) / (precision + recall)
  cat(paste(&quot;Accuracy:\t&quot;, format(accuracy, digits=2), &quot;\n&quot;,sep=&quot; &quot;))
  cat(paste(&quot;Precision:\t&quot;, format(precision, digits=2), &quot;\n&quot;,sep=&quot; &quot;))
  cat(paste(&quot;Recall:\t\t&quot;, format(recall, digits=2), &quot;\n&quot;,sep=&quot; &quot;))
  cat(paste(&quot;F-measure:\t&quot;, format(f, digits=2), &quot;\n&quot;,sep=&quot; &quot;))
}
evaluation(tree, validationData, &quot;class&quot;)</code></pre>
<pre><code>## 
## Confusion matrix:
##            
## prediction  benign malignant
##   benign       138         6
##   malignant      6        64
## 
## Evaluation:
## 
## Accuracy:     0.94 
## Precision:    0.96 
## Recall:       0.96 
## F-measure:    0.96</code></pre>
<pre class="r"><code>evaluation(entTree, validationData, &quot;class&quot;)</code></pre>
<pre><code>## 
## Confusion matrix:
##            
## prediction  benign malignant
##   benign       138         5
##   malignant      6        65
## 
## Evaluation:
## 
## Accuracy:     0.95 
## Precision:    0.96 
## Recall:       0.97 
## F-measure:    0.96</code></pre>
<pre class="r"><code>evaluation(tree_with_params, validationData, &quot;class&quot;)</code></pre>
<pre><code>## 
## Confusion matrix:
##            
## prediction  benign malignant
##   benign       139        12
##   malignant      5        58
## 
## Evaluation:
## 
## Accuracy:     0.92 
## Precision:    0.97 
## Recall:       0.92 
## F-measure:    0.94</code></pre>
<pre class="r"><code>evaluation(ctree, validationData, &quot;response&quot;)</code></pre>
<pre><code>## 
## Confusion matrix:
##            
## prediction  benign malignant
##   benign       138         6
##   malignant      6        64
## 
## Evaluation:
## 
## Accuracy:     0.94 
## Precision:    0.96 
## Recall:       0.96 
## F-measure:    0.96</code></pre>
</div>

<h2>Acknowledgements</h2>

<p>The tutorials, besides including the author's original contributions and knowledge of Machine Learning algorithms and R, also include contributions from other material and more specifically: 1) from an introductory R leaflet from the Pattern Recognition course leaflets of the Electrical and Computer Engineering Department of the Aristotle University of Thessaloniki (Fall semester 2016, authors: Themistoklis Diamantopoulos/Michalis Papamichail, professor: Andreas Symeonidis), 2) the leaflet from the course CS545 Machine Learnig (Fall 2008, author and professor: Charles W. Anderson) and 3) <a href="https://software-carpentry.org/">Software Caprentry</a> lessons like <a href="http://swcarpentry.github.io/r-novice-inflammation/">Programming in R</a> from which the inflammation data were also included.</p>

<h2>License</h2>

<p>This work is made available under the <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution license</a>.</p>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-2782275-11', 'auto');
  ga('send', 'pageview');
</script>



</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
